{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e22700c5",
   "metadata": {},
   "source": [
    "# MANDATE - 2 :  (MT2021069)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985bc39c",
   "metadata": {},
   "source": [
    "### In this notebook, i have tried to experiment few unsupervised techniques for running a QA model with the use of sentence embedding generated in previous notebook and the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b8a68c",
   "metadata": {},
   "source": [
    "### The Unsupervised techniques (Euclidean distance & Cosine Similarity) used in this notebook are just implemented to show how sentence embedding (vectorization) helps in solving the problem. These techniques are not final models but just for experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fe9f35",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries and Packages :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8337f9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import json\n",
    "import ast \n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "import torch\n",
    "import pickle\n",
    "from scipy import spatial\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import spacy\n",
    "from nltk import Tree\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "st = LancasterStemmer()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b865231",
   "metadata": {},
   "source": [
    "### Training Pandas Dataframe, generarted in previous notebook :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90e0d7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r\"C:\\Users\\admin\\Downloads\\t11.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eb5816a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87599, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d567103c",
   "metadata": {},
   "source": [
    "### Loading Embedding Dictionary (Generated in previous notebook) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd496df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\admin\\dataN\\dict_embeddings1.pickle', 'rb') as handle:\n",
    "    d1 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d50f438",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\admin\\dataN\\dict_embeddings2.pickle', 'rb') as handle:\n",
    "    d2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0025358",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_emb = dict(d1)\n",
    "dict_emb.update(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fdc623d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179857"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29de471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del d1, d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73df9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79be6879",
   "metadata": {},
   "source": [
    "## Data Processing :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2447737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(x):\n",
    "    idx = -1\n",
    "    for i in range(len(x[\"sentences\"])):\n",
    "        if x[\"text\"] in x[\"sentences\"][i]: idx = i\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad8ae6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>515</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>188</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>279</td>\n",
       "      <td>the Main Building</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  answer_start  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...           515   \n",
       "1  What is in front of the Notre Dame Main Building?           188   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...           279   \n",
       "\n",
       "                         text  \n",
       "0  Saint Bernadette Soubirous  \n",
       "1   a copper statue of Christ  \n",
       "2           the Main Building  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "757d126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d9a1632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87598, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1da64c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(train):\n",
    "    \n",
    "    print(\"step 1\")\n",
    "    train['sentences'] = train['context'].apply(lambda x: [item.raw for item in TextBlob(x).sentences])\n",
    "    \n",
    "    print(\"step 2\")\n",
    "    train[\"target\"] = train.apply(get_target, axis = 1)\n",
    "    \n",
    "    print(\"step 3\")\n",
    "    train['sent_emb'] = train['sentences'].apply(lambda x: [dict_emb[item][0] if item in\\\n",
    "                                                           dict_emb else np.zeros(4096) for item in x])\n",
    "    print(\"step 4\")\n",
    "    train['quest_emb'] = train['question'].apply(lambda x: dict_emb[x] if x in dict_emb else np.zeros(4096) )\n",
    "        \n",
    "    return train  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4503a046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1\n",
      "step 2\n",
      "step 3\n",
      "step 4\n"
     ]
    }
   ],
   "source": [
    "train = process_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ebecc26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>target</th>\n",
       "      <th>sent_emb</th>\n",
       "      <th>quest_emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>515</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>[Architecturally, the school has a Catholic ch...</td>\n",
       "      <td>5</td>\n",
       "      <td>[[-0.015412132, -0.054134972, 0.014491863, -0....</td>\n",
       "      <td>[[0.0074688885, 0.024210272, 0.06961634, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>188</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>[Architecturally, the school has a Catholic ch...</td>\n",
       "      <td>2</td>\n",
       "      <td>[[-0.015412132, -0.054134972, 0.014491863, -0....</td>\n",
       "      <td>[[0.0074688885, -0.033483382, 0.040545914, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>279</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>[Architecturally, the school has a Catholic ch...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[-0.015412132, -0.054134972, 0.014491863, -0....</td>\n",
       "      <td>[[0.0074688885, -0.043944724, 0.1438594, -0.00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  answer_start  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...           515   \n",
       "1  What is in front of the Notre Dame Main Building?           188   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...           279   \n",
       "\n",
       "                         text  \\\n",
       "0  Saint Bernadette Soubirous   \n",
       "1   a copper statue of Christ   \n",
       "2           the Main Building   \n",
       "\n",
       "                                           sentences  target  \\\n",
       "0  [Architecturally, the school has a Catholic ch...       5   \n",
       "1  [Architecturally, the school has a Catholic ch...       2   \n",
       "2  [Architecturally, the school has a Catholic ch...       3   \n",
       "\n",
       "                                            sent_emb  \\\n",
       "0  [[-0.015412132, -0.054134972, 0.014491863, -0....   \n",
       "1  [[-0.015412132, -0.054134972, 0.014491863, -0....   \n",
       "2  [[-0.015412132, -0.054134972, 0.014491863, -0....   \n",
       "\n",
       "                                           quest_emb  \n",
       "0  [[0.0074688885, 0.024210272, 0.06961634, -0.01...  \n",
       "1  [[0.0074688885, -0.033483382, 0.040545914, -0....  \n",
       "2  [[0.0074688885, -0.043944724, 0.1438594, -0.00...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fcf5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fbcf70d",
   "metadata": {},
   "source": [
    "## Predicted Cosine and Euclidean Index :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77a1486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(x):\n",
    "    li = []\n",
    "    for item in x[\"sent_emb\"]:\n",
    "        li.append(spatial.distance.cosine(item,x[\"quest_emb\"][0]))\n",
    "    return li   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a245abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_idx(distances):\n",
    "    return np.argmin(distances)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee7b259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(train):\n",
    "    \n",
    "    train[\"cosine_sim\"] = train.apply(cosine_sim, axis = 1)\n",
    "    train[\"diff\"] = (train[\"quest_emb\"] - train[\"sent_emb\"])**2\n",
    "    train[\"euclidean_dis\"] = train[\"diff\"].apply(lambda x: list(np.sum(x, axis = 1)))\n",
    "    del train[\"diff\"]\n",
    "    \n",
    "    print(\"cosine start\")\n",
    "    \n",
    "    train[\"pred_idx_cos\"] = train[\"cosine_sim\"].apply(lambda x: pred_idx(x))\n",
    "    train[\"pred_idx_euc\"] = train[\"euclidean_dis\"].apply(lambda x: pred_idx(x))\n",
    "    \n",
    "    return train\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80426b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine start\n"
     ]
    }
   ],
   "source": [
    "predicted = predictions(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbe184fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_start</th>\n",
       "      <th>text</th>\n",
       "      <th>sentences</th>\n",
       "      <th>target</th>\n",
       "      <th>sent_emb</th>\n",
       "      <th>quest_emb</th>\n",
       "      <th>cosine_sim</th>\n",
       "      <th>euclidean_dis</th>\n",
       "      <th>pred_idx_cos</th>\n",
       "      <th>pred_idx_euc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>515</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>[Architecturally, the school has a Catholic ch...</td>\n",
       "      <td>5</td>\n",
       "      <td>[[-0.015412132, -0.054134972, 0.014491863, -0....</td>\n",
       "      <td>[[0.0074688885, 0.024210272, 0.06961634, -0.01...</td>\n",
       "      <td>[0.7483252286911011, 0.6157153248786926, 0.616...</td>\n",
       "      <td>[8.731496, 7.767769, 8.243154, 7.9353786, 7.73...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>188</td>\n",
       "      <td>a copper statue of Christ</td>\n",
       "      <td>[Architecturally, the school has a Catholic ch...</td>\n",
       "      <td>2</td>\n",
       "      <td>[[-0.015412132, -0.054134972, 0.014491863, -0....</td>\n",
       "      <td>[[0.0074688885, -0.033483382, 0.040545914, -0....</td>\n",
       "      <td>[0.7264537513256073, 0.5839367210865021, 0.654...</td>\n",
       "      <td>[7.0554705, 6.2977524, 7.563771, 4.9111557, 6....</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>279</td>\n",
       "      <td>the Main Building</td>\n",
       "      <td>[Architecturally, the school has a Catholic ch...</td>\n",
       "      <td>3</td>\n",
       "      <td>[[-0.015412132, -0.054134972, 0.014491863, -0....</td>\n",
       "      <td>[[0.0074688885, -0.043944724, 0.1438594, -0.00...</td>\n",
       "      <td>[0.6630303263664246, 0.5432414710521698, 0.575...</td>\n",
       "      <td>[6.4743433, 5.8934736, 6.712471, 4.1032743, 4....</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "1  Architecturally, the school has a Catholic cha...   \n",
       "2  Architecturally, the school has a Catholic cha...   \n",
       "\n",
       "                                            question  answer_start  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...           515   \n",
       "1  What is in front of the Notre Dame Main Building?           188   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...           279   \n",
       "\n",
       "                         text  \\\n",
       "0  Saint Bernadette Soubirous   \n",
       "1   a copper statue of Christ   \n",
       "2           the Main Building   \n",
       "\n",
       "                                           sentences  target  \\\n",
       "0  [Architecturally, the school has a Catholic ch...       5   \n",
       "1  [Architecturally, the school has a Catholic ch...       2   \n",
       "2  [Architecturally, the school has a Catholic ch...       3   \n",
       "\n",
       "                                            sent_emb  \\\n",
       "0  [[-0.015412132, -0.054134972, 0.014491863, -0....   \n",
       "1  [[-0.015412132, -0.054134972, 0.014491863, -0....   \n",
       "2  [[-0.015412132, -0.054134972, 0.014491863, -0....   \n",
       "\n",
       "                                           quest_emb  \\\n",
       "0  [[0.0074688885, 0.024210272, 0.06961634, -0.01...   \n",
       "1  [[0.0074688885, -0.033483382, 0.040545914, -0....   \n",
       "2  [[0.0074688885, -0.043944724, 0.1438594, -0.00...   \n",
       "\n",
       "                                          cosine_sim  \\\n",
       "0  [0.7483252286911011, 0.6157153248786926, 0.616...   \n",
       "1  [0.7264537513256073, 0.5839367210865021, 0.654...   \n",
       "2  [0.6630303263664246, 0.5432414710521698, 0.575...   \n",
       "\n",
       "                                       euclidean_dis  pred_idx_cos  \\\n",
       "0  [8.731496, 7.767769, 8.243154, 7.9353786, 7.73...             5   \n",
       "1  [7.0554705, 6.2977524, 7.563771, 4.9111557, 6....             3   \n",
       "2  [6.4743433, 5.8934736, 6.712471, 4.1032743, 4....             3   \n",
       "\n",
       "   pred_idx_euc  \n",
       "0             5  \n",
       "1             3  \n",
       "2             3  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "963f8150",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted.to_csv(r'C:\\Users\\Admin\\Downloads\\predictedNLP1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8006fef",
   "metadata": {},
   "source": [
    "## Accuracy :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ab52728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(target, predicted):\n",
    "    \n",
    "    acc = (target==predicted).sum()/len(target)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d389a7b3",
   "metadata": {},
   "source": [
    "### Accuracy for Euclidean Distance :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3ea6784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49163222904632525\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(predicted[\"target\"], predicted[\"pred_idx_euc\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c460d2",
   "metadata": {},
   "source": [
    "### Accuracy for Cosine Similarity :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd19c0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6198657503595972\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(predicted[\"target\"], predicted[\"pred_idx_cos\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "103091b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted.to_csv(r'C:\\Users\\Admin\\Downloads\\predEx.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b07327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e79271ce",
   "metadata": {},
   "source": [
    "### Accuracy of Cosine Similarity is better because it takes into consideration the angle between the vectors which the Euclidean Distance doesn't."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6607962f",
   "metadata": {},
   "source": [
    "### In the above techniques, in data processing i have not implemented stemming on sentences and questions as it was just for the purpose of experimentation, but will surely implement it while training future advance models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207efe4a",
   "metadata": {},
   "source": [
    "# Next Goals :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7931967",
   "metadata": {},
   "source": [
    "#### 1. Implement Advance Supervised Models and train them to get better accuracy on SQuAD.\n",
    "#### 2. The \"Bhagwad Gita\" dataset generation is under process, once it is ready will apply all these methodologies experimented on SQuAD dataset on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be818fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
